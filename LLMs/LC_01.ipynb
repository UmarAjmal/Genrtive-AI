{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019af4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.8\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54022170",
   "metadata": {},
   "source": [
    "# LangChain LLM - Super Easy Explanation üöÄ\n",
    "\n",
    "## LLM kya hai?\n",
    "\n",
    "**LLM (Large Language Model)** - Yeh AI models hain jo text samajhte aur generate karte hain, jaise ChatGPT, Claude, etc.\n",
    "\n",
    "## LangChain mein LLM kaise use hote hain?\n",
    "\n",
    "### 1. **Basic Setup** üîß\n",
    "\n",
    "````python\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# LLM initialize karo\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,  # Creativity level (0-1)\n",
    "    api_key=\"your-api-key\"\n",
    ")\n",
    "\n",
    "# Simple question poocho\n",
    "response = llm.invoke(\"Pakistan ki capital kya hai?\")\n",
    "print(response.content)\n",
    "````\n",
    "\n",
    "### 2. **Different LLM Providers** üåê\n",
    "\n",
    "````python\n",
    "# OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Google (Gemini)\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "# Anthropic (Claude)\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
    "````\n",
    "\n",
    "### 3. **Prompt Templates ke saath** üìù\n",
    "\n",
    "````python\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Template banao\n",
    "template = \"\"\"\n",
    "Tum aik {role} ho. \n",
    "Sawaal: {question}\n",
    "Jawab Urdu mein do.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"role\", \"question\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# Chain banao\n",
    "chain = prompt | llm\n",
    "\n",
    "# Use karo\n",
    "result = chain.invoke({\n",
    "    \"role\": \"teacher\",\n",
    "    \"question\": \"Photosynthesis kya hai?\"\n",
    "})\n",
    "print(result.content)\n",
    "````\n",
    "\n",
    "### 4. **Important Parameters** ‚öôÔ∏è\n",
    "\n",
    "- **temperature**: 0 (strict) se 1 (creative)\n",
    "- **max_tokens**: Kitne words generate karenge\n",
    "- **model**: Konsa model use karenge\n",
    "\n",
    "### 5. **Streaming Response** üì°\n",
    "\n",
    "````python\n",
    "llm = ChatOpenAI(streaming=True)\n",
    "\n",
    "for chunk in llm.stream(\"AI ke bare mein batao\"):\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "````\n",
    "\n",
    "## Key Points üéØ\n",
    "\n",
    "‚úÖ LLM = AI brain jo text samajhta hai  \n",
    "‚úÖ LangChain = LLM ko easily use karne ka tool  \n",
    "‚úÖ Multiple providers support (OpenAI, Google, etc.)  \n",
    "‚úÖ Prompts customize kar sakte ho  \n",
    "‚úÖ Streaming bhi kar sakte ho\n",
    "\n",
    "**Installation:**\n",
    "```bash\n",
    "pip install langchain langchain-openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79176bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "result = llm(\"What is the capital of France?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
