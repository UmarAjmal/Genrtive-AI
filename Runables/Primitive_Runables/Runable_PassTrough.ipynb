{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': 'Why did the AI program go to therapy?\\n\\nBecause it was struggling to process its emotions.', 'explanation': 'This joke plays on the double meaning of the word \"process\" and the concept of therapy.\\n\\nHere\\'s the breakdown:\\n\\n1.  **Human Context (Therapy):** When humans go to therapy, they often do so because they are \"struggling to process their emotions.\" This means they are having difficulty understanding, coping with, integrating, or dealing with complex feelings like sadness, anger, anxiety, etc. Therapy helps them work through these internal states.\\n\\n2.  **AI/Computer Context:**\\n    *   **\"Process\" (literal):** For an AI or any computer program, \"processing\" is its fundamental function. It means to perform operations on data, to analyze, compute, or transform information.\\n    *   **\"Emotions\" (data):** While AI doesn\\'t *feel* emotions in the human sense, it can be programmed to *detect* and *analyze* emotional data (e.g., sentiment analysis in text, facial expression recognition).\\n\\n3.  **The Joke\\'s Humor:**\\n    *   **Personification:** The joke personifies the AI by giving it a very human problem (emotional struggle) and a human solution (therapy).\\n    *   **Wordplay:** The humor comes from the pun on \"process.\"\\n        *   For a human, \"processing emotions\" is a psychological task.\\n        *   For an AI, \"processing emotions\" would be an incredibly complex *data processing* task, given the subjective, nuanced, and often contradictory nature of human feelings. The idea of an AI struggling with this \"data\" in a way that mirrors human emotional struggle is what makes it funny.\\n    *   **Absurdity:** The idea of a logical, data-driven machine needing help with something as inherently non-logical and complex as emotions is inherently amusing and highlights the vast difference between human and artificial intelligence.\\n\\nIn short, the joke works by applying a very human problem and solution to an AI, using a word (\"process\") that has both a psychological meaning for humans and a literal, fundamental meaning for computers, creating a humorous juxtaposition.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableBranch, RunnableLambda\n",
    "from langchain_core.runnables import RunnableSequence, RunnablePassthrough\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key_01 = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "api_key_02 = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=api_key_01,\n",
    "    temperature=0.1 # Lower temperature for better JSON generation\n",
    ")\n",
    "\n",
    "model_01 = ChatHuggingFace(llm=llm) \n",
    "\n",
    "model_02 = ChatGoogleGenerativeAI(model = \"gemini-2.5-flash\", temperature=0.1, api_key=api_key_02)  \n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "prompt_01 = PromptTemplate(\n",
    "    template=\"Write a joke relevant to the following topic: {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt_02 = PromptTemplate(\n",
    "    template=\"Expin the following joke: {joke}\",\n",
    "    input_variables=[\"joke\"]\n",
    ")\n",
    "\n",
    "joke_gen_chain = RunnableSequence(\n",
    "    prompt_01 | model_01 | str_parser\n",
    ")\n",
    "\n",
    "parallel_chain = RunnableParallel(\n",
    "    {\n",
    "        'joke': RunnablePassthrough(),\n",
    "        'explanation': RunnableSequence(prompt_02 | model_02 | str_parser)\n",
    "    }\n",
    ")\n",
    "\n",
    "final_chain = RunnableSequence(\n",
    "    joke_gen_chain | parallel_chain\n",
    ")\n",
    "\n",
    "result = final_chain.invoke({\"topic\": \"Artificial Intelligence\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfa3990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        +-------------+                     \n",
      "                        | PromptInput |                     \n",
      "                        +-------------+                     \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                       +----------------+                   \n",
      "                       | PromptTemplate |                   \n",
      "                       +----------------+                   \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                      +-----------------+                   \n",
      "                      | ChatHuggingFace |                   \n",
      "                      +-----------------+                   \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                      +-----------------+                   \n",
      "                      | StrOutputParser |                   \n",
      "                      +-----------------+                   \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "              +---------------------------------+           \n",
      "              | Parallel<joke,explanation>Input |           \n",
      "              +---------------------------------+           \n",
      "                     ****               ***                 \n",
      "                  ***                      ***              \n",
      "                **                            ***           \n",
      "    +----------------+                           **         \n",
      "    | PromptTemplate |                            *         \n",
      "    +----------------+                            *         \n",
      "             *                                    *         \n",
      "             *                                    *         \n",
      "             *                                    *         \n",
      "+------------------------+                        *         \n",
      "| ChatGoogleGenerativeAI |                        *         \n",
      "+------------------------+                        *         \n",
      "             *                                    *         \n",
      "             *                                    *         \n",
      "             *                                    *         \n",
      "    +-----------------+                    +-------------+  \n",
      "    | StrOutputParser |                    | Passthrough |  \n",
      "    +-----------------+                    +-------------+  \n",
      "                     ****               ***                 \n",
      "                         ***         ***                    \n",
      "                            **     **                       \n",
      "              +----------------------------------+          \n",
      "              | Parallel<joke,explanation>Output |          \n",
      "              +----------------------------------+          \n"
     ]
    }
   ],
   "source": [
    "final_chain.get_graph().print_ascii()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
