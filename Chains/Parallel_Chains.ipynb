{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ad890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the merged document combining your notes and quiz about Sequential Chains:\n",
      "\n",
      "---\n",
      "\n",
      "# Sequential Chain Ka Samajh: Notes & Quiz\n",
      "\n",
      "## Understanding Sequential Chains\n",
      "\n",
      "1.  **Sequential chain** ek workflow hai jo multiple chains ko ek-ek karke execute karta hai.\n",
      "2.  **Pehla chain ka output** doosre chain ka input ban jata hai.\n",
      "3.  **Iska sahi se upyog** complex tasks, reusable code, debugging, flexible workflows, aur professional applications ke liye hai.\n",
      "\n",
      "### Key Features\n",
      "\n",
      "*   **Steps**: Multiple prompts, multiple models\n",
      "*   **Flow**: Step-by-step\n",
      "*   **Complexity**: Advanced\n",
      "*   **Use Case**: Multi-step tasks\n",
      "\n",
      "### Real-World Example\n",
      "\n",
      "*   **Task**: Book ke baare mein detailed summary likho.\n",
      "*   **Steps**:\n",
      "    1.  **Step 1**: Book ke baare mein basic info generate karo.\n",
      "    2.  **Step 2**: Us info se detailed summary likho.\n",
      "    3.  **Step 3**: Summary se key takeaways nikalo.\n",
      "\n",
      "### Code Example: Implementing a Sequential Flow\n",
      "\n",
      "```python\n",
      "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
      "from langchain_core.prompts import PromptTemplate\n",
      "from langchain_core.output_parsers import StrOutputParser\n",
      "from dotenv import load_dotenv\n",
      "import os\n",
      "\n",
      "# Setup Environment\n",
      "load_dotenv()\n",
      "api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
      "\n",
      "# Initialize LLM\n",
      "llm = HuggingFaceEndpoint(\n",
      "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
      "    task=\"text-generation\",\n",
      "    huggingfacehub_api_token=api_key,\n",
      "    temperature=0.3,\n",
      "    max_new_tokens=200\n",
      ")\n",
      "\n",
      "model = ChatHuggingFace(llm=llm)\n",
      "str_parser = StrOutputParser()\n",
      "\n",
      "# ============ STEP 1: Generate Book Info ============\n",
      "prompt_1 = PromptTemplate(\n",
      "    template=\"Provide basic information about the book '{book_name}' in 3 lines. Include author, genre, and publication year.\",\n",
      "    input_variables=[\"book_name\"]\n",
      ")\n",
      "chain_1 = prompt_1 | model | str_parser\n",
      "\n",
      "# ============ STEP 2: Generate Summary ============\n",
      "prompt_2 = PromptTemplate(\n",
      "    template=\"Based on this book information: {book_info}\\n\\nNow write a detailed summary of the book in 5 points.\",\n",
      "    input_variables=[\"book_info\"]\n",
      ")\n",
      "chain_2 = prompt_2 | model | str_parser\n",
      "\n",
      "# ============ STEP 3: Extract Key Takeaways ============\n",
      "prompt_3 = PromptTemplate(\n",
      "    template=\"From this summary: {summary_text}\\n\\nExtract 3 key takeaways.\",\n",
      "    input_variables=[\"summary_text\"]\n",
      ")\n",
      "chain_3 = prompt_3 | model | str_parser\n",
      "\n",
      "# ============ Conceptual Sequential Execution Example ============\n",
      "if __name__ == \"__main__\":\n",
      "    book_to_summarize = \"The Alchemist\"\n",
      "\n",
      "    print(f\"--- Starting Sequential Chain for: {book_to_summarize} ---\")\n",
      "\n",
      "    # Step 1 Execution\n",
      "    print(\"\\n--- Running Step 1: Generate Book Info ---\")\n",
      "    book_info_output = chain_1.invoke({\"book_name\": book_to_summarize})\n",
      "    print(f\"Generated Book Info:\\n{book_info_output}\")\n",
      "\n",
      "    # Step 2 Execution (Input from Step 1)\n",
      "    print(\"\\n--- Running Step 2: Generate Summary ---\")\n",
      "    summary_output = chain_2.invoke({\"book_info\": book_info_output})\n",
      "    print(f\"Generated Summary:\\n{summary_output}\")\n",
      "\n",
      "    # Step 3 Execution (Input from Step 2)\n",
      "    print(\"\\n--- Running Step 3: Extract Key Takeaways ---\")\n",
      "    key_takeaways_output = chain_3.invoke({\"summary_text\": summary_output})\n",
      "    print(f\"Extracted Key Takeaways:\\n{key_takeaways_output}\")\n",
      "\n",
      "    print(\"\\n--- Sequential Chain Completed ---\")\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## Quiz\n",
      "\n",
      "Here are 5 short questions from the text:\n",
      "\n",
      "1.  **What is a Sequential Chain?**\n",
      "2.  **How many prompts and models does a Simple Chain use compared to a Sequential Chain?**\n",
      "3.  **In a Sequential Chain, what is the relationship between the output of an earlier step and the input of the next step?**\n",
      "4.  **Name one key advantage of using Sequential Chains.**\n",
      "5.  **According to the \"Real-World Example\", what are the three sequential steps to write a detailed summary of a book?**\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Step 1: Load API key from .env file\n",
    "load_dotenv()\n",
    "api_key_01 = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "api_key_02 = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Step 2: Select a parser for the output (in this case, a simple string parser)\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "# Step 3: Initialize the HuggingFaceEndpoint with the desired model and task\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=api_key_01\n",
    ")\n",
    "\n",
    "# Step 4: Initialize the models for both HuggingFace and Google Generative AI\n",
    "model_01 = ChatHuggingFace(llm=llm)\n",
    "model_02 = ChatGoogleGenerativeAI(model = \"gemini-2.5-flash\", temperature=0.7, api_key = api_key_02)\n",
    "\n",
    "# Step 5: Create prompt templates for generating notes and quiz questions\n",
    "prompt_01 = PromptTemplate(\n",
    "    template='Generate a short notes form the following text: {text}',\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "prompt_02 = PromptTemplate(\n",
    "    template='Generate 5 short questions from the following text: {text}',\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "prompt_03 = PromptTemplate(\n",
    "    template='Merge notes and quiz into a single documnet \\n Notes: {notes} \\n Quiz: {quiz} .',\n",
    "    input_variables=[\"notes\", \"quiz\"]   \n",
    ")\n",
    "\n",
    "# Step 6: Create a parallel chain that runs both the notes and quiz generation simultaneously\n",
    "parallel_chain = RunnableParallel({\n",
    "    'notes': prompt_01 | model_01 | str_parser,\n",
    "    'quiz': prompt_02 | model_02 | str_parser\n",
    "})\n",
    "\n",
    "# Step 7: Create a merge chain that takes the outputs of the parallel chain and merges them into a single document\n",
    "merge_chain  = prompt_03 | model_02 | str_parser\n",
    "\n",
    "# Step 8: Combine the parallel chain and the merge chain into a single chain\n",
    "chain = parallel_chain | merge_chain\n",
    "\n",
    "# Step 9: Invoke the chain with a sample text input\n",
    "text = \"\"\"# Sequential Chains in LangChain - Detailed Explanation\n",
    "\n",
    "## Sequential Chain Kya Hota Hai?\n",
    "\n",
    "**Sequential Chain** ek workflow hai jisme multiple chains ek-ek karke execute hote hain. Pehle chain ka output, doosre chain ka input ban jaata hai.\n",
    "\n",
    "---\n",
    "\n",
    "## Sequential vs Simple Chain\n",
    "\n",
    "| Feature | Simple Chain | Sequential Chain |\n",
    "|---------|------------|-----------------|\n",
    "| **Steps** | 1 prompt ‚Üí 1 model | Multiple prompts ‚Üí Multiple models |\n",
    "| **Flow** | Linear (ek hi) | Step-by-step (multiple) |\n",
    "| **Complexity** | Simple | Advanced |\n",
    "| **Use Case** | Single task | Multi-step tasks |\n",
    "\n",
    "---\n",
    "\n",
    "## Sequential Chain Ka Structure\n",
    "\n",
    "```\n",
    "Step 1: Prompt 1 ‚Üí Model 1 ‚Üí Parser 1 (Output A)\n",
    "         ‚Üì\n",
    "Step 2: Prompt 2 (Input A) ‚Üí Model 2 ‚Üí Parser 2 (Output B)\n",
    "         ‚Üì\n",
    "Step 3: Prompt 3 (Input B) ‚Üí Model 3 ‚Üí Parser 3 (Final Output)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Example\n",
    "\n",
    "**Task:** Kisi book ke baare mein detailed summary likho\n",
    "\n",
    "**Sequential Steps:**\n",
    "\n",
    "1Ô∏è‚É£ **Step 1**: Book ke baare mein basic info generate karo  \n",
    "2Ô∏è‚É£ **Step 2**: Us info se detailed summary likho  \n",
    "3Ô∏è‚É£ **Step 3**: Summary se key takeaways nikalo  \n",
    "\n",
    "---\n",
    "\n",
    "## Code Example - Sequential Chain\n",
    "\n",
    "````python\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Setup\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=api_key,\n",
    "    temperature=0.3,\n",
    "    max_new_tokens=200\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "# ============ STEP 1: Generate Book Info ============\n",
    "prompt_1 = PromptTemplate(\n",
    "    template=\"Provide basic information about the book '{book_name}' in 3 lines. Include author, genre, and publication year.\",\n",
    "    input_variables=[\"book_name\"]\n",
    ")\n",
    "\n",
    "chain_1 = prompt_1 | model | str_parser\n",
    "\n",
    "# ============ STEP 2: Generate Summary ============\n",
    "prompt_2 = PromptTemplate(\n",
    "    template=\"Based on this book information: {book_info}\\n\\nNow write a detailed summary of the book in 5 points.\",\n",
    "    input_variables=[\"book_info\"]\n",
    ")\n",
    "\n",
    "chain_2 = prompt_2 | model | str_parser\n",
    "\n",
    "# ============ STEP 3: Extract Key Takeaways ============\n",
    "prompt_3 = PromptTemplate(\n",
    "    template=\"From this summary: {summary}\\n\\nExtract 3 most important key takeaways from the book.\",\n",
    "    input_variables=[\"summary\"]\n",
    ")\n",
    "\n",
    "chain_3 = prompt_3 | model | str_parser\n",
    "\n",
    "# ============ EXECUTE SEQUENTIAL CHAIN ============\n",
    "print(\"=== STEP 1: Book Information ===\")\n",
    "book_info = chain_1.invoke({\"book_name\": \"1984\"})\n",
    "print(book_info)\n",
    "\n",
    "print(\"\\n=== STEP 2: Detailed Summary ===\")\n",
    "summary = chain_2.invoke({\"book_info\": book_info})\n",
    "print(summary)\n",
    "\n",
    "print(\"\\n=== STEP 3: Key Takeaways ===\")\n",
    "takeaways = chain_3.invoke({\"summary\": summary})\n",
    "print(takeaways)\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## Using RunnableSequence (Advanced)\n",
    "\n",
    "````python\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Method 1: Manual Sequential Execution (Recommended for clarity)\n",
    "def execute_sequential(book_name):\n",
    "    info = chain_1.invoke({\"book_name\": book_name})\n",
    "    summary = chain_2.invoke({\"book_info\": info})\n",
    "    takeaways = chain_3.invoke({\"summary\": summary})\n",
    "    \n",
    "    return {\n",
    "        \"book_info\": info,\n",
    "        \"summary\": summary,\n",
    "        \"takeaways\": takeaways\n",
    "    }\n",
    "\n",
    "result = execute_sequential(\"To Kill a Mockingbird\")\n",
    "print(result)\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## LangChain's SequentialChain (Older Method)\n",
    "\n",
    "````python\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# Define chains with memory\n",
    "chain_1 = LLMChain(llm=model, prompt=prompt_1, output_key=\"book_info\")\n",
    "chain_2 = LLMChain(llm=model, prompt=prompt_2, output_key=\"summary\")\n",
    "chain_3 = LLMChain(llm=model, prompt=prompt_3, output_key=\"takeaways\")\n",
    "\n",
    "# Create sequential chain\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_1, chain_2, chain_3],\n",
    "    input_variables=[\"book_name\"],\n",
    "    output_variables=[\"book_info\", \"summary\", \"takeaways\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = overall_chain({\"book_name\": \"1984\"})\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## Real Example: Article Writing Workflow\n",
    "\n",
    "````python\n",
    "# STEP 1: Generate Title\n",
    "prompt_title = PromptTemplate(\n",
    "    template=\"Generate an engaging article title about {topic}.\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "chain_title = prompt_title | model | str_parser\n",
    "\n",
    "# STEP 2: Generate Outline\n",
    "prompt_outline = PromptTemplate(\n",
    "    template=\"Given the title '{title}', create a 5-point article outline.\",\n",
    "    input_variables=[\"title\"]\n",
    ")\n",
    "chain_outline = prompt_outline | model | str_parser\n",
    "\n",
    "# STEP 3: Write Full Article\n",
    "prompt_article = PromptTemplate(\n",
    "    template=\"Using this outline:\\n{outline}\\n\\nWrite a detailed article.\",\n",
    "    input_variables=[\"outline\"]\n",
    ")\n",
    "chain_article = prompt_article | model | str_parser\n",
    "\n",
    "# EXECUTE\n",
    "print(\"Step 1: Generating Title...\")\n",
    "title = chain_title.invoke({\"topic\": \"Artificial Intelligence\"})\n",
    "\n",
    "print(\"Step 2: Generating Outline...\")\n",
    "outline = chain_outline.invoke({\"title\": title})\n",
    "\n",
    "print(\"Step 3: Writing Article...\")\n",
    "article = chain_article.invoke({\"outline\": outline})\n",
    "\n",
    "print(\"\\n=== FINAL ARTICLE ===\")\n",
    "print(article)\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## Sequential Chain Flow Diagram\n",
    "\n",
    "```\n",
    "INPUT: User Request\n",
    "    ‚Üì\n",
    "STEP 1: Process Input\n",
    "    ‚îú‚îÄ Prompt Template\n",
    "    ‚îú‚îÄ LLM Model\n",
    "    ‚îî‚îÄ Output Parser ‚Üí Output A\n",
    "    ‚Üì\n",
    "STEP 2: Use Output A as Input\n",
    "    ‚îú‚îÄ Prompt Template (with Output A)\n",
    "    ‚îú‚îÄ LLM Model\n",
    "    ‚îî‚îÄ Output Parser ‚Üí Output B\n",
    "    ‚Üì\n",
    "STEP 3: Use Output B as Input\n",
    "    ‚îú‚îÄ Prompt Template (with Output B)\n",
    "    ‚îú‚îÄ LLM Model\n",
    "    ‚îî‚îÄ Output Parser ‚Üí Final Output\n",
    "    ‚Üì\n",
    "OUTPUT: Final Result\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Key Advantages\n",
    "\n",
    "‚úÖ **Complex Tasks** - Multi-step workflows ko handle karta hai  \n",
    "‚úÖ **Reusable** - Har step independently use ho sakta hai  \n",
    "‚úÖ **Debugging** - Har step ka output dekhna aasan  \n",
    "‚úÖ **Flexible** - Output of one step ‚Üí Input of next  \n",
    "‚úÖ **Professional** - Production-level applications  \n",
    "\n",
    "---\n",
    "\n",
    "## Common Use Cases\n",
    "\n",
    "1. **Content Generation**\n",
    "   - Title ‚Üí Outline ‚Üí Full Article\n",
    "\n",
    "2. **Question Answering**\n",
    "   - Extract Context ‚Üí Understand Question ‚Üí Generate Answer\n",
    "\n",
    "3. **Code Generation**\n",
    "   - Understand Request ‚Üí Plan Solution ‚Üí Generate Code\n",
    "\n",
    "4. **Research**\n",
    "   - Search Topic ‚Üí Summarize ‚Üí Create Report\n",
    "\n",
    "5. **Translation + Summarization**\n",
    "   - Translate Text ‚Üí Summarize ‚Üí Extract Key Points\n",
    "\n",
    "---\n",
    "\n",
    "## Error Handling in Sequential Chains\n",
    "\n",
    "````python\n",
    "def execute_with_error_handling(book_name):\n",
    "    try:\n",
    "        print(\"Step 1: Fetching book info...\")\n",
    "        info = chain_1.invoke({\"book_name\": book_name})\n",
    "        if not info:\n",
    "            raise ValueError(\"Step 1 failed: No book info generated\")\n",
    "        \n",
    "        print(\"Step 2: Generating summary...\")\n",
    "        summary = chain_2.invoke({\"book_info\": info})\n",
    "        if not summary:\n",
    "            raise ValueError(\"Step 2 failed: No summary generated\")\n",
    "        \n",
    "        print(\"Step 3: Extracting takeaways...\")\n",
    "        takeaways = chain_3.invoke({\"summary\": summary})\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"book_info\": info,\n",
    "            \"summary\": summary,\n",
    "            \"takeaways\": takeaways\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error_message\": str(e)\n",
    "        }\n",
    "\n",
    "result = execute_with_error_handling(\"1984\")\n",
    "print(result)\n",
    "````\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "üîπ **Sequential = Step-by-step execution**  \n",
    "üîπ **Output of Step N ‚Üí Input of Step N+1**  \n",
    "üîπ **Multiple prompts, multiple models**  \n",
    "üîπ **Excellent for complex workflows**  \n",
    "üîπ **Easy debugging and monitoring**  \n",
    "\n",
    "**Bas Itna Samajh Loo: Sequential Chain = Pehla chain ‚Üí Doosra chain ‚Üí Teesra chain** ‚úÖ\"\"\"\n",
    "\n",
    "# Step 10: Invoke the chain with the sample text\n",
    "result = chain.invoke({'text': text})\n",
    "\n",
    "# Step 11: Print the final response\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c5361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               +---------------------------+                     \n",
      "               | Parallel<notes,quiz>Input |                     \n",
      "               +---------------------------+                     \n",
      "                  ****                 ***                       \n",
      "               ***                        ****                   \n",
      "             **                               **                 \n",
      "+----------------+                       +----------------+      \n",
      "| PromptTemplate |                       | PromptTemplate |      \n",
      "+----------------+                       +----------------+      \n",
      "          *                                       *              \n",
      "          *                                       *              \n",
      "          *                                       *              \n",
      "+-----------------+                  +------------------------+  \n",
      "| ChatHuggingFace |                  | ChatGoogleGenerativeAI |  \n",
      "+-----------------+                  +------------------------+  \n",
      "          *                                       *              \n",
      "          *                                       *              \n",
      "          *                                       *              \n",
      "+-----------------+                     +-----------------+      \n",
      "| StrOutputParser |                     | StrOutputParser |      \n",
      "+-----------------+                     +-----------------+      \n",
      "                  ****                 ***                       \n",
      "                      ***          ****                          \n",
      "                         **      **                              \n",
      "               +----------------------------+                    \n",
      "               | Parallel<notes,quiz>Output |                    \n",
      "               +----------------------------+                    \n",
      "                              *                                  \n",
      "                              *                                  \n",
      "                              *                                  \n",
      "                     +----------------+                          \n",
      "                     | PromptTemplate |                          \n",
      "                     +----------------+                          \n",
      "                              *                                  \n",
      "                              *                                  \n",
      "                              *                                  \n",
      "                 +------------------------+                      \n",
      "                 | ChatGoogleGenerativeAI |                      \n",
      "                 +------------------------+                      \n",
      "                              *                                  \n",
      "                              *                                  \n",
      "                              *                                  \n",
      "                    +-----------------+                          \n",
      "                    | StrOutputParser |                          \n",
      "                    +-----------------+                          \n",
      "                              *                                  \n",
      "                              *                                  \n",
      "                              *                                  \n",
      "                 +-----------------------+                       \n",
      "                 | StrOutputParserOutput |                       \n",
      "                 +-----------------------+                       \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
